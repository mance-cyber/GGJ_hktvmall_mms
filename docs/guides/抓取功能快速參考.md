# æŠ“å–åŠŸèƒ½å¿«é€Ÿåƒè€ƒå¡

> 5 åˆ†é˜é€ŸæŸ¥æ‰‹å†Š

---

## ğŸš€ å¿«é€Ÿé–‹å§‹

```python
# 1. å°å…¥é€£æ¥å™¨
from app.connectors.firecrawl import get_firecrawl_connector

# 2. ç²å–å¯¦ä¾‹
connector = get_firecrawl_connector()

# 3. æŠ“å–å•†å“
info = connector.extract_product_info("https://example.com/product/123")

# 4. ä½¿ç”¨æ•¸æ“š
print(f"{info.name}: HK${info.price}")
```

---

## ğŸ“š å¸¸ç”¨æ“ä½œ

### æŠ“å–å–®å€‹å•†å“

```python
info = connector.extract_product_info(url)

# è¨ªå•å±¬æ€§
info.name              # å•†å“åç¨±
info.price             # åƒ¹æ ¼ (Decimal)
info.original_price    # åŸåƒ¹
info.discount_percent  # æŠ˜æ‰£ç™¾åˆ†æ¯”
info.stock_status      # åº«å­˜ç‹€æ…‹
info.rating            # è©•åˆ†
info.review_count      # è©•è«–æ•¸
info.image_url         # åœ–ç‰‡ URL
info.sku               # SKU
info.brand             # å“ç‰Œ
```

### è™•ç†å‹•æ…‹é é¢

```python
info = connector.extract_product_info(
    url=url,
    use_actions=True  # å•Ÿç”¨ JavaScript è™•ç†
)
```

### ç™¼ç¾å•†å“ URL

```python
urls = connector.discover_product_urls(
    base_url="https://shop.com",
    keywords=["product", "å•†å“"]
)
```

### æ‰¹é‡æŠ“å–

```python
for url in url_list:
    info = connector.extract_product_info(url)
    # è™•ç† info...
    time.sleep(2)  # é¿å…è«‹æ±‚éå¿«
```

---

## ğŸ› ï¸ é€²éšç”¨æ³•

### è‡ªå®šç¾© Actions

```python
actions = [
    {"type": "wait", "milliseconds": 2000},
    {"type": "click", "selector": "button.show-price"},
    {"type": "scroll", "direction": "down", "amount": 500},
]

raw_data = connector.scrape_with_actions(
    url=url,
    actions=actions,
    take_screenshot=True
)
```

### ç²å–åŸå§‹æ•¸æ“š

```python
raw_data = connector.scrape_url(
    url=url,
    use_json_mode=True,
    wait_for=5000
)

print(raw_data['json'])      # AI æå–çš„çµæ§‹åŒ–æ•¸æ“š
print(raw_data['markdown'])  # Markdown æ ¼å¼
print(raw_data['html'])      # HTML åŸå§‹ç¢¼
```

### éŒ¯èª¤è™•ç†

```python
try:
    info = connector.extract_product_info(url)
except ValueError:
    print("API Key æœªè¨­å®š")
except ConnectionError:
    print("ç¶²è·¯é€£æ¥å¤±æ•—")
except Exception as e:
    print(f"æœªçŸ¥éŒ¯èª¤: {e}")
```

---

## âš™ï¸ é…ç½®

### .env æ–‡ä»¶

```env
FIRECRAWL_API_KEY=fc-your-api-key-here
DATABASE_URL=postgresql+asyncpg://...
REDIS_URL=redis://localhost:6379/0
```

### ç²å–è¨­å®š

```python
from app.config import get_settings

settings = get_settings()
print(settings.firecrawl_api_key)
```

---

## ğŸ”§ Celery ç•°æ­¥ä»»å‹™

### æŠ“å–å–®å€‹å•†å“

```python
from app.tasks.scrape_tasks import scrape_single_product

task = scrape_single_product.delay(product_id)
result = task.get(timeout=30)
```

### æŠ“å–ç«¶çˆ­å°æ‰‹

```python
from app.tasks.scrape_tasks import scrape_competitor

task = scrape_competitor.delay(competitor_id)
```

### æ‰¹é‡æŠ“å–

```python
from app.tasks.scrape_tasks import scrape_all_competitors

task = scrape_all_competitors.delay()
```

---

## âš¡ æ€§èƒ½å„ªåŒ–

### æ¸›å°‘ç­‰å¾…æ™‚é–“

```python
raw_data = connector.scrape_url(
    url=url,
    wait_for=1000  # åƒ…ç­‰å¾… 1 ç§’
)
```

### è·³é JSON Mode

```python
raw_data = connector.scrape_url(
    url=url,
    use_json_mode=False  # ç›´æ¥è§£æ HTML
)
```

### ä¸¦è¡ŒæŠ“å–

```python
from concurrent.futures import ThreadPoolExecutor

with ThreadPoolExecutor(max_workers=3) as executor:
    results = executor.map(
        lambda u: connector.extract_product_info(u),
        url_list
    )
```

---

## ğŸ› å¸¸è¦‹éŒ¯èª¤

| éŒ¯èª¤ | åŸå›  | è§£æ±ºæ–¹æ¡ˆ |
|------|------|---------|
| `API Key æœªè¨­å®š` | ç’°å¢ƒè®Šæ•¸ç¼ºå¤± | åœ¨ .env è¨­å®š `FIRECRAWL_API_KEY` |
| `429 Too Many Requests` | è«‹æ±‚éå¿« | æ·»åŠ  `time.sleep(2)` |
| `åƒ¹æ ¼ç‚º None` | è§£æå¤±æ•— | æª¢æŸ¥ç¶²ç«™æ ¼å¼ï¼Œæˆ–ä½¿ç”¨ JSON Mode |
| `ImportError` | å¥—ä»¶æœªå®‰è£ | `pip install firecrawl-py==0.0.16` |

---

## ğŸ§ª æ¸¬è©¦æŒ‡ä»¤

```bash
# é‹è¡Œæ¸¬è©¦è…³æœ¬
cd backend
python test_scraping.py

# æ¸¬è©¦è‡ªå®šç¾© URL
python test_scraping.py "https://example.com/product/123"

# äº¤äº’å¼æ¸¬è©¦
python
>>> from app.connectors.firecrawl import get_firecrawl_connector
>>> connector = get_firecrawl_connector()
>>> info = connector.extract_product_info("https://...")
```

---

## ğŸ“Š æ•¸æ“šé©—è­‰

```python
def validate(info):
    """é©—è­‰å•†å“è³‡è¨Š"""
    checks = {
        "åç¨±": bool(info.name and info.name != "æœªçŸ¥å•†å“"),
        "åƒ¹æ ¼": bool(info.price and info.price > 0),
        "åœ–ç‰‡": bool(info.image_url),
    }

    for name, passed in checks.items():
        print(f"{'âœ“' if passed else 'âœ—'} {name}")

    return all(checks.values())
```

---

## ğŸ“ æ”¯æ´è³‡æº

- **å®Œæ•´æ•™å­¸**: `docs/å¤–éƒ¨æŠ“å–åŠŸèƒ½å®Œæ•´æ•™å­¸.md`
- **ä»£ç¢¼ä½ç½®**: `backend/app/connectors/firecrawl.py`
- **æ¸¬è©¦è…³æœ¬**: `backend/test_scraping.py`
- **å®˜æ–¹æ–‡æª”**: https://docs.firecrawl.dev

---

## ğŸ’¡ æœ€ä½³å¯¦è¸

1. âœ… ä½¿ç”¨ JSON Mode å„ªå…ˆ
2. âœ… æ·»åŠ è«‹æ±‚é–“éš” (2 ç§’)
3. âœ… å®Œæ•´éŒ¯èª¤è™•ç†
4. âœ… é©—è­‰æŠ“å–çµæœ
5. âœ… è¨˜éŒ„é—œéµæ“ä½œæ—¥èªŒ
6. âŒ ä¸è¦ç„¡é™åˆ¶ä¸¦ç™¼
7. âŒ ä¸è¦å¿½ç•¥éŒ¯èª¤
8. âŒ ä¸è¦ç¡¬ç·¨ç¢¼ API Key

---

**ç‰ˆæœ¬**: v1.0 | **æ›´æ–°**: 2026-01-06
