# =============================================
# AI æœå‹™ - æ”¯æŒä¸­è½‰ç«™ (è‡ªå®šç¾© Base URL)
# =============================================

from typing import Optional, Dict, Any, List
from dataclasses import dataclass, field
from enum import Enum
import httpx
import json
from datetime import datetime

from sqlalchemy.ext.asyncio import AsyncSession
from sqlalchemy import select

from app.models.system import SystemSetting
from app.config import get_settings


# =============================================
# ä»»å‹™è¤‡é›œåº¦æšèˆ‰
# =============================================

class TaskComplexity(str, Enum):
    """ä»»å‹™è¤‡é›œåº¦ç­‰ç´š"""
    SIMPLE = "simple"      # ç°¡å–®ä»»å‹™ï¼šç«¶å“æ˜ å°„ã€SEO é—œéµè©ã€åŸºç¤åˆ†æ
    MEDIUM = "medium"      # ä¸­ç­‰ä»»å‹™ï¼šæ–‡æ¡ˆç”Ÿæˆã€å®šåƒ¹åˆ†æã€å…§å®¹å„ªåŒ–
    COMPLEX = "complex"    # è¤‡é›œä»»å‹™ï¼šå¸‚å ´ç°¡å ±ã€æˆ°ç•¥å»ºè­°ã€æ·±åº¦åˆ†æ


# å¸¸ç”¨æ¨¡å‹åˆ—è¡¨
AVAILABLE_MODELS = [
    # Claude 4.x ç³»åˆ—ï¼ˆæœ€æ–°ï¼‰
    {"id": "claude-opus-4-6-thinking", "name": "Claude Opus 4.6 Thinking", "description": "æœ€å¼·æ€è€ƒæ¨¡å‹ï¼ˆä¸­è½‰ APIï¼‰"},
    {"id": "claude-haiku-4-5-20251001-thinking", "name": "Claude Haiku 4.5 Thinking", "description": "ç¶“æ¿Ÿæ€è€ƒæ¨¡å‹ï¼ˆä¸­è½‰ APIï¼‰"},
    {"id": "claude-opus-4-6-20250229", "name": "Claude Opus 4.6", "description": "æœ€æ–°æœ€å¼·å¤§æ¨¡å‹"},
    {"id": "claude-sonnet-4-5-20250929", "name": "Claude Sonnet 4.5", "description": "æœ€æ–°å¹³è¡¡æ¨¡å‹"},
    {"id": "claude-sonnet-4-20250514", "name": "Claude Sonnet 4", "description": "å¹³è¡¡æ¨¡å‹"},
    {"id": "claude-opus-4-20250514", "name": "Claude Opus 4", "description": "å¼·å¤§æ¨¡å‹"},
    # Claude 3.x ç³»åˆ—
    {"id": "claude-3-5-sonnet-20241022", "name": "Claude 3.5 Sonnet", "description": "é«˜æ€§åƒ¹æ¯”"},
    {"id": "claude-3-5-haiku-20241022", "name": "Claude 3.5 Haiku", "description": "å¿«é€Ÿç¶“æ¿Ÿ"},
    {"id": "claude-3-opus-20240229", "name": "Claude 3 Opus", "description": "èˆŠç‰ˆæœ€å¼·"},
    {"id": "claude-3-sonnet-20240229", "name": "Claude 3 Sonnet", "description": "èˆŠç‰ˆå¹³è¡¡"},
    {"id": "claude-3-haiku-20240307", "name": "Claude 3 Haiku", "description": "èˆŠç‰ˆå¿«é€Ÿ"},
    # GPT ç³»åˆ—
    {"id": "gpt-4o", "name": "GPT-4o", "description": "OpenAI æœ€æ–°"},
    {"id": "gpt-4o-mini", "name": "GPT-4o Mini", "description": "å¿«é€Ÿç¶“æ¿Ÿ"},
    {"id": "gpt-4-turbo", "name": "GPT-4 Turbo", "description": "GPT-4 å¿«é€Ÿç‰ˆ"},
    {"id": "gpt-4", "name": "GPT-4", "description": "å¼·å¤§ç©©å®š"},
    {"id": "gpt-3.5-turbo", "name": "GPT-3.5 Turbo", "description": "ç¶“æ¿Ÿå¯¦æƒ "},
    # DeepSeek ç³»åˆ—
    {"id": "deepseek-chat", "name": "DeepSeek Chat", "description": "DeepSeek å°è©±"},
    {"id": "deepseek-coder", "name": "DeepSeek Coder", "description": "DeepSeek ä»£ç¢¼"},
    # å…¶ä»–
    {"id": "custom", "name": "è‡ªå®šç¾©æ¨¡å‹", "description": "è¼¸å…¥ä»»æ„æ¨¡å‹åç¨±"},
]


def _get_default_base_url() -> str:
    """ç²å–é è¨­ Base URLï¼ˆå¾é…ç½®è®€å–ï¼‰"""
    return get_settings().openai_base_url


def _get_default_model() -> str:
    """ç²å–é è¨­æ¨¡å‹ï¼ˆå¾é…ç½®è®€å–ï¼‰"""
    return get_settings().openai_default_model


@dataclass
class AIConfig:
    """AI é…ç½®ï¼ˆæ”¯æŒå¤šæ¨¡å‹åˆ†ç´šï¼‰"""
    api_key: str = ""
    base_url: str = field(default_factory=_get_default_base_url)  # API ç«¯é»

    # å–®æ¨¡å‹é…ç½®ï¼ˆå‘å¾Œå…¼å®¹ï¼‰
    insights_model: str = field(default_factory=_get_default_model)  # æ•¸æ“šæ‘˜è¦
    strategy_model: str = field(default_factory=_get_default_model)  # ç­–ç•¥å»ºè­°

    # å¤šæ¨¡å‹åˆ†ç´šé…ç½®ï¼ˆæ–°å¢ï¼‰
    simple_model: str = "claude-haiku-4-5-20251001-thinking"    # ç°¡å–®ä»»å‹™
    medium_model: str = "claude-opus-4-6-thinking"               # ä¸­ç­‰ä»»å‹™
    complex_model: str = "claude-opus-4-6-thinking"              # è¤‡é›œä»»å‹™

    def get_model_by_complexity(self, complexity: TaskComplexity) -> str:
        """æ ¹æ“šä»»å‹™è¤‡é›œåº¦è¿”å›å°æ‡‰æ¨¡å‹"""
        if complexity == TaskComplexity.SIMPLE:
            return self.simple_model
        elif complexity == TaskComplexity.MEDIUM:
            return self.medium_model
        else:  # COMPLEX
            return self.complex_model


@dataclass
class AIResponse:
    """AI éŸ¿æ‡‰"""
    content: str
    model: str
    tokens_used: int = 0
    success: bool = True
    error: Optional[str] = None


class AISettingsService:
    """AI è¨­å®šæœå‹™ - ç®¡ç† API Keyã€Base URL å’Œæ¨¡å‹é¸æ“‡ï¼ˆæ”¯æŒå¤šæ¨¡å‹åˆ†ç´šï¼‰"""

    # è¨­å®šéµå
    KEY_API_KEY = "ai_api_key"
    KEY_BASE_URL = "ai_base_url"
    KEY_INSIGHTS_MODEL = "ai_insights_model"
    KEY_STRATEGY_MODEL = "ai_strategy_model"

    # å¤šæ¨¡å‹åˆ†ç´šè¨­å®šï¼ˆæ–°å¢ï¼‰
    KEY_SIMPLE_MODEL = "ai_simple_model"
    KEY_MEDIUM_MODEL = "ai_medium_model"
    KEY_COMPLEX_MODEL = "ai_complex_model"

    @classmethod
    async def get_config(cls, db: AsyncSession) -> AIConfig:
        """ç²å– AI é…ç½®ï¼ˆæ”¯æŒå¤šæ¨¡å‹åˆ†ç´šï¼‰"""
        settings_obj = get_settings()
        config = AIConfig()

        # å„ªå…ˆå¾ç’°å¢ƒè®Šæ•¸è®€å–
        if settings_obj.ai_api_key or settings_obj.anthropic_api_key:
            config.api_key = settings_obj.ai_api_key or settings_obj.anthropic_api_key
        if settings_obj.ai_base_url:
            config.base_url = settings_obj.ai_base_url

        # å¤šæ¨¡å‹åˆ†ç´šé…ç½®ï¼ˆå„ªå…ˆå¾ç’°å¢ƒè®Šæ•¸ï¼‰
        config.simple_model = settings_obj.ai_model_simple
        config.medium_model = settings_obj.ai_model_medium
        config.complex_model = settings_obj.ai_model_complex

        # è®€å–æ•¸æ“šåº«è¨­å®šï¼ˆå¯è¦†è“‹ç’°å¢ƒè®Šæ•¸ï¼‰
        result = await db.execute(
            select(SystemSetting).where(
                SystemSetting.key.in_([
                    cls.KEY_API_KEY,
                    cls.KEY_BASE_URL,
                    cls.KEY_INSIGHTS_MODEL,
                    cls.KEY_STRATEGY_MODEL,
                    cls.KEY_SIMPLE_MODEL,
                    cls.KEY_MEDIUM_MODEL,
                    cls.KEY_COMPLEX_MODEL,
                ])
            )
        )
        settings = {s.key: s.value for s in result.scalars().all()}

        if cls.KEY_API_KEY in settings:
            config.api_key = settings[cls.KEY_API_KEY]
        if cls.KEY_BASE_URL in settings:
            config.base_url = settings[cls.KEY_BASE_URL]
        if cls.KEY_INSIGHTS_MODEL in settings:
            config.insights_model = settings[cls.KEY_INSIGHTS_MODEL]
        if cls.KEY_STRATEGY_MODEL in settings:
            config.strategy_model = settings[cls.KEY_STRATEGY_MODEL]

        # å¤šæ¨¡å‹é…ç½®ï¼ˆæ•¸æ“šåº«å„ªå…ˆï¼‰
        if cls.KEY_SIMPLE_MODEL in settings:
            config.simple_model = settings[cls.KEY_SIMPLE_MODEL]
        if cls.KEY_MEDIUM_MODEL in settings:
            config.medium_model = settings[cls.KEY_MEDIUM_MODEL]
        if cls.KEY_COMPLEX_MODEL in settings:
            config.complex_model = settings[cls.KEY_COMPLEX_MODEL]

        return config

    @classmethod
    async def save_config(
        cls,
        db: AsyncSession,
        api_key: Optional[str] = None,
        base_url: Optional[str] = None,
        insights_model: Optional[str] = None,
        strategy_model: Optional[str] = None,
        simple_model: Optional[str] = None,
        medium_model: Optional[str] = None,
        complex_model: Optional[str] = None,
    ) -> AIConfig:
        """ä¿å­˜ AI é…ç½®ï¼ˆæ”¯æŒå¤šæ¨¡å‹åˆ†ç´šï¼‰"""
        updates = {}
        if api_key is not None:
            updates[cls.KEY_API_KEY] = api_key
        if base_url is not None:
            # ç¢ºä¿ URL æ ¼å¼æ­£ç¢º
            base_url = base_url.rstrip('/')
            updates[cls.KEY_BASE_URL] = base_url
        if insights_model is not None:
            updates[cls.KEY_INSIGHTS_MODEL] = insights_model
        if strategy_model is not None:
            updates[cls.KEY_STRATEGY_MODEL] = strategy_model

        # å¤šæ¨¡å‹é…ç½®
        if simple_model is not None:
            updates[cls.KEY_SIMPLE_MODEL] = simple_model
        if medium_model is not None:
            updates[cls.KEY_MEDIUM_MODEL] = medium_model
        if complex_model is not None:
            updates[cls.KEY_COMPLEX_MODEL] = complex_model

        for key, value in updates.items():
            existing = await db.execute(
                select(SystemSetting).where(SystemSetting.key == key)
            )
            setting = existing.scalar_one_or_none()

            if setting:
                setting.value = value
                setting.updated_at = datetime.utcnow()
            else:
                setting = SystemSetting(
                    key=key,
                    value=value,
                    description=f"AI è¨­å®š: {key}"
                )
                db.add(setting)

        await db.commit()
        return await cls.get_config(db)

    @classmethod
    async def test_connection(cls, api_key: str, base_url: str, model: str = "gpt-3.5-turbo") -> Dict[str, Any]:
        """æ¸¬è©¦ API é€£æ¥æ˜¯å¦æœ‰æ•ˆï¼ˆOpenAI æ ¼å¼ï¼‰"""
        base_url = base_url.rstrip('/')

        try:
            async with httpx.AsyncClient(timeout=30.0) as client:
                response = await client.post(
                    f"{base_url}/chat/completions",
                    headers={
                        "Authorization": f"Bearer {api_key}",
                        "Content-Type": "application/json",
                    },
                    json={
                        "model": model,
                        "messages": [{"role": "user", "content": "Hi"}],
                        "max_tokens": 10,
                    }
                )

                if response.status_code == 200:
                    return {"valid": True, "message": "é€£æ¥æˆåŠŸï¼"}
                elif response.status_code == 401:
                    return {"valid": False, "error": "API Key ç„¡æ•ˆæˆ–å·²éæœŸ"}
                elif response.status_code == 404:
                    return {"valid": False, "error": "API ç«¯é»ä¸å­˜åœ¨ï¼Œè«‹æª¢æŸ¥ Base URL"}
                else:
                    error_text = response.text[:200] if response.text else "Unknown error"
                    return {"valid": False, "error": f"API éŒ¯èª¤ ({response.status_code}): {error_text}"}

        except httpx.ConnectError:
            return {"valid": False, "error": "ç„¡æ³•é€£æ¥åˆ°æœå‹™å™¨ï¼Œè«‹æª¢æŸ¥ Base URL"}
        except httpx.TimeoutException:
            return {"valid": False, "error": "é€£æ¥è¶…æ™‚ï¼Œè«‹æª¢æŸ¥ç¶²çµ¡æˆ–æœå‹™å™¨ç‹€æ…‹"}
        except Exception as e:
            return {"valid": False, "error": f"æ¸¬è©¦å¤±æ•—: {str(e)}"}

    @classmethod
    async def test_claude_connection(
        cls,
        api_key: str,
        base_url: str,
        model: str = "claude-haiku-4-5-20251001-thinking"
    ) -> Dict[str, Any]:
        """
        æ¸¬è©¦ Claude API é€£æ¥ï¼ˆAnthropic æ ¼å¼ï¼‰

        ç”¨æ–¼æ¸¬è©¦ GPT-Best ç­‰ä¸­è½‰ API æ˜¯å¦èƒ½æ­£å¸¸èª¿ç”¨ Claude æ¨¡å‹
        """
        base_url = base_url.rstrip('/')

        try:
            async with httpx.AsyncClient(timeout=60.0) as client:
                response = await client.post(
                    f"{base_url}/messages",
                    headers={
                        "x-api-key": api_key,
                        "anthropic-version": "2023-06-01",
                        "Content-Type": "application/json",
                    },
                    json={
                        "model": model,
                        "max_tokens": 50,
                        "messages": [
                            {"role": "user", "content": "è«‹ç”¨ä¸€å¥è©±å›è¦†ï¼šä½ å¥½"}
                        ]
                    }
                )

                if response.status_code == 200:
                    data = response.json()
                    content = data.get("content", [{}])[0].get("text", "")
                    usage = data.get("usage", {})
                    input_tokens = usage.get("input_tokens", 0)
                    output_tokens = usage.get("output_tokens", 0)

                    return {
                        "valid": True,
                        "message": "âœ… Claude API é€£æ¥æˆåŠŸï¼",
                        "model": model,
                        "response": content,
                        "tokens": {
                            "input": input_tokens,
                            "output": output_tokens,
                            "total": input_tokens + output_tokens
                        }
                    }
                elif response.status_code == 401:
                    return {
                        "valid": False,
                        "error": "âŒ API Key ç„¡æ•ˆæˆ–å·²éæœŸ",
                        "status_code": 401
                    }
                elif response.status_code == 404:
                    return {
                        "valid": False,
                        "error": f"âŒ ç«¯é»ä¸å­˜åœ¨: {base_url}/messages\nè«‹ç¢ºèª Base URL æ˜¯å¦æ­£ç¢º",
                        "status_code": 404,
                        "hint": "æ­£ç¢ºæ ¼å¼ä¾‹å¦‚ï¼šhttps://api.gpt-best.com/v1"
                    }
                elif response.status_code == 400:
                    error_data = response.json() if response.text else {}
                    error_msg = error_data.get("error", {}).get("message", response.text[:200])
                    return {
                        "valid": False,
                        "error": f"âŒ è«‹æ±‚éŒ¯èª¤: {error_msg}",
                        "status_code": 400,
                        "hint": f"å¯èƒ½åŸå› ï¼šæ¨¡å‹ '{model}' ä¸å­˜åœ¨æˆ–ä¸å¯ç”¨"
                    }
                else:
                    error_text = response.text[:300] if response.text else "Unknown error"
                    return {
                        "valid": False,
                        "error": f"âŒ API éŒ¯èª¤ ({response.status_code}): {error_text}",
                        "status_code": response.status_code
                    }

        except httpx.ConnectError:
            return {
                "valid": False,
                "error": "âŒ ç„¡æ³•é€£æ¥åˆ°æœå‹™å™¨",
                "hint": f"è«‹æª¢æŸ¥ Base URL: {base_url}"
            }
        except httpx.TimeoutException:
            return {
                "valid": False,
                "error": "âŒ é€£æ¥è¶…æ™‚ï¼ˆ60ç§’ï¼‰",
                "hint": "è«‹æª¢æŸ¥ç¶²çµ¡é€£æ¥æˆ–æœå‹™å™¨ç‹€æ…‹"
            }
        except Exception as e:
            return {
                "valid": False,
                "error": f"âŒ æ¸¬è©¦å¤±æ•—: {str(e)}"
            }

    @classmethod
    async def test_environment_config(cls) -> Dict[str, Any]:
        """
        æ¸¬è©¦ç’°å¢ƒè®Šæ•¸é…ç½®

        ä¸èª¿ç”¨ APIï¼Œåªæª¢æŸ¥ Zeabur ç’°å¢ƒè®Šæ•¸æ˜¯å¦æ­£ç¢ºè¼‰å…¥
        """
        settings_obj = get_settings()

        # æª¢æŸ¥å„é …é…ç½®
        config_status = {
            "ai_base_url": {
                "value": settings_obj.ai_base_url,
                "set": bool(settings_obj.ai_base_url and settings_obj.ai_base_url != "https://api.anthropic.com"),
                "source": "ç’°å¢ƒè®Šæ•¸ AI_BASE_URL"
            },
            "ai_api_key": {
                "value": f"{settings_obj.ai_api_key[:8]}...{settings_obj.ai_api_key[-4:]}" if settings_obj.ai_api_key and len(settings_obj.ai_api_key) > 12 else "***",
                "set": bool(settings_obj.ai_api_key),
                "source": "ç’°å¢ƒè®Šæ•¸ AI_API_KEY"
            },
            "anthropic_api_key": {
                "value": f"{settings_obj.anthropic_api_key[:8]}...{settings_obj.anthropic_api_key[-4:]}" if settings_obj.anthropic_api_key and len(settings_obj.anthropic_api_key) > 12 else "***",
                "set": bool(settings_obj.anthropic_api_key),
                "source": "ç’°å¢ƒè®Šæ•¸ ANTHROPIC_API_KEYï¼ˆå®˜æ–¹ APIï¼‰"
            },
            "ai_model_simple": {
                "value": settings_obj.ai_model_simple,
                "set": True,
                "source": "ç’°å¢ƒè®Šæ•¸ AI_MODEL_SIMPLE"
            },
            "ai_model_medium": {
                "value": settings_obj.ai_model_medium,
                "set": True,
                "source": "ç’°å¢ƒè®Šæ•¸ AI_MODEL_MEDIUM"
            },
            "ai_model_complex": {
                "value": settings_obj.ai_model_complex,
                "set": True,
                "source": "ç’°å¢ƒè®Šæ•¸ AI_MODEL_COMPLEX"
            }
        }

        # åˆ¤æ–·æ•´é«”ç‹€æ…‹
        using_relay_api = config_status["ai_base_url"]["set"]
        has_api_key = config_status["ai_api_key"]["set"] or config_status["anthropic_api_key"]["set"]

        # ç”Ÿæˆå»ºè­°
        recommendations = []
        if not using_relay_api:
            recommendations.append("âš ï¸ AI_BASE_URL æœªè¨­ç½®æˆ–ä½¿ç”¨é è¨­å€¼ï¼Œç›®å‰ä½¿ç”¨ Anthropic å®˜æ–¹ API")
            recommendations.append("ğŸ’¡ è‹¥è¦ä½¿ç”¨ GPT-Best ä¸­è½‰ APIï¼Œè«‹è¨­ç½®ï¼šAI_BASE_URL=https://api.gpt-best.com/v1")

        if not config_status["ai_api_key"]["set"] and using_relay_api:
            recommendations.append("âš ï¸ ä½¿ç”¨ä¸­è½‰ API ä½† AI_API_KEY æœªè¨­ç½®")
            recommendations.append("ğŸ’¡ è«‹åœ¨ Zeabur æ·»åŠ ç’°å¢ƒè®Šæ•¸ï¼šAI_API_KEY=<ä½ çš„ GPT-Best API Key>")

        if not has_api_key:
            recommendations.append("âŒ æœªè¨­ç½®ä»»ä½• API Keyï¼ŒAI åŠŸèƒ½å°‡ç„¡æ³•ä½¿ç”¨")

        return {
            "status": "ready" if (using_relay_api and config_status["ai_api_key"]["set"]) or (not using_relay_api and config_status["anthropic_api_key"]["set"]) else "incomplete",
            "using_relay_api": using_relay_api,
            "has_api_key": has_api_key,
            "config": config_status,
            "recommendations": recommendations,
            "summary": f"{'âœ… é…ç½®å®Œæ•´' if has_api_key else 'âŒ é…ç½®ä¸å®Œæ•´'} | {'ä½¿ç”¨ä¸­è½‰ API' if using_relay_api else 'ä½¿ç”¨å®˜æ–¹ API'}"
        }

    @classmethod
    def get_available_models(cls) -> List[Dict[str, str]]:
        """ç²å–é è¨­å¯ç”¨æ¨¡å‹åˆ—è¡¨"""
        return AVAILABLE_MODELS

    @classmethod
    async def fetch_models_from_api(
        cls,
        api_key: str,
        base_url: str
    ) -> Dict[str, Any]:
        """
        å¾ API å‹•æ…‹ç²å–å¯ç”¨æ¨¡å‹åˆ—è¡¨

        å¤§å¤šæ•¸ OpenAI å…¼å®¹ API éƒ½æ”¯æŒ /models ç«¯é»

        Returns:
            {
                "success": bool,
                "models": [{"id": "...", "name": "...", "owned_by": "..."}],
                "error": str | None
            }
        """
        base_url = base_url.rstrip('/')

        try:
            async with httpx.AsyncClient(timeout=30.0) as client:
                response = await client.get(
                    f"{base_url}/models",
                    headers={
                        "Authorization": f"Bearer {api_key}",
                        "Content-Type": "application/json",
                    }
                )

                if response.status_code == 200:
                    data = response.json()
                    models_data = data.get("data", [])

                    # è™•ç†æ¨¡å‹åˆ—è¡¨
                    models = []
                    for m in models_data:
                        model_id = m.get("id", "")
                        # éæ¿¾æ‰éèŠå¤©æ¨¡å‹ï¼ˆå¦‚ embeddingã€whisper ç­‰ï¼‰
                        if any(skip in model_id.lower() for skip in [
                            "embedding", "whisper", "tts", "dall-e",
                            "moderation", "search", "similarity"
                        ]):
                            continue

                        models.append({
                            "id": model_id,
                            "name": cls._format_model_name(model_id),
                            "owned_by": m.get("owned_by", "unknown"),
                            "created": m.get("created"),
                        })

                    # æŒ‰åç¨±æ’åº
                    models.sort(key=lambda x: x["name"])

                    return {
                        "success": True,
                        "models": models,
                        "total": len(models)
                    }

                elif response.status_code == 401:
                    return {
                        "success": False,
                        "models": [],
                        "error": "API Key ç„¡æ•ˆ"
                    }
                elif response.status_code == 404:
                    # æŸäº›ä¸­è½‰ç«™å¯èƒ½ä¸æ”¯æŒ /models ç«¯é»
                    return {
                        "success": False,
                        "models": [],
                        "error": "æ­¤ API ä¸æ”¯æŒç²å–æ¨¡å‹åˆ—è¡¨ï¼Œè«‹æ‰‹å‹•é¸æ“‡æ¨¡å‹"
                    }
                else:
                    return {
                        "success": False,
                        "models": [],
                        "error": f"API éŒ¯èª¤ ({response.status_code})"
                    }

        except httpx.ConnectError:
            return {
                "success": False,
                "models": [],
                "error": "ç„¡æ³•é€£æ¥åˆ°æœå‹™å™¨"
            }
        except httpx.TimeoutException:
            return {
                "success": False,
                "models": [],
                "error": "é€£æ¥è¶…æ™‚"
            }
        except Exception as e:
            return {
                "success": False,
                "models": [],
                "error": f"ç²å–å¤±æ•—: {str(e)}"
            }

    @classmethod
    def _format_model_name(cls, model_id: str) -> str:
        """æ ¼å¼åŒ–æ¨¡å‹åç¨±ï¼Œä½¿å…¶æ›´æ˜“è®€"""
        # å¸¸è¦‹æ¨¡å‹çš„å‹å¥½åç¨±æ˜ å°„
        friendly_names = {
            "gpt-4o": "GPT-4o",
            "gpt-4o-mini": "GPT-4o Mini",
            "gpt-4-turbo": "GPT-4 Turbo",
            "gpt-4": "GPT-4",
            "gpt-3.5-turbo": "GPT-3.5 Turbo",
            "claude-3-opus": "Claude 3 Opus",
            "claude-3-sonnet": "Claude 3 Sonnet",
            "claude-3-haiku": "Claude 3 Haiku",
            "claude-3-5-sonnet": "Claude 3.5 Sonnet",
            "claude-3-5-haiku": "Claude 3.5 Haiku",
            "claude-sonnet-4": "Claude Sonnet 4",
            "claude-opus-4": "Claude Opus 4",
            "deepseek-chat": "DeepSeek Chat",
            "deepseek-coder": "DeepSeek Coder",
        }

        # æª¢æŸ¥æ˜¯å¦æœ‰åŒ¹é…çš„å‹å¥½åç¨±
        for key, name in friendly_names.items():
            if model_id.startswith(key):
                return name

        # å¦å‰‡è¿”å›åŸå§‹ IDï¼ˆé¦–å­—æ¯å¤§å¯«ï¼‰
        return model_id.replace("-", " ").title()


class AIAnalysisService:
    """AI åˆ†ææœå‹™ - åŸ·è¡Œæ•¸æ“šæ‘˜è¦å’Œç­–ç•¥ç”Ÿæˆ"""

    def __init__(self, config: AIConfig):
        self.config = config
        self.base_url = config.base_url.rstrip('/')

    def _call_api(self, prompt: str, model: str, max_tokens: int = 2048) -> AIResponse:
        """èª¿ç”¨ OpenAI å…¼å®¹ APIï¼ˆåŒæ­¥ç‰ˆæœ¬ï¼‰"""
        if not self.config.api_key:
            return AIResponse(
                content="",
                model="",
                success=False,
                error="API Key æœªè¨­å®š"
            )

        try:
            import httpx
            
            with httpx.Client(timeout=120.0) as client:
                response = client.post(
                    f"{self.base_url}/chat/completions",
                    headers={
                        "Authorization": f"Bearer {self.config.api_key}",
                        "Content-Type": "application/json",
                    },
                    json={
                        "model": model,
                        "messages": [{"role": "user", "content": prompt}],
                        "max_tokens": max_tokens,
                    }
                )

                if response.status_code != 200:
                    error_text = response.text[:300] if response.text else "Unknown error"
                    return AIResponse(
                        content="",
                        model=model,
                        success=False,
                        error=f"API éŒ¯èª¤ ({response.status_code}): {error_text}"
                    )

                data = response.json()
                content = data.get("choices", [{}])[0].get("message", {}).get("content", "")
                usage = data.get("usage", {})
                tokens = usage.get("total_tokens", 0)

                return AIResponse(
                    content=content,
                    model=model,
                    tokens_used=tokens,
                    success=True
                )

        except httpx.ConnectError:
            return AIResponse(
                content="",
                model=model,
                success=False,
                error="ç„¡æ³•é€£æ¥åˆ° API æœå‹™å™¨"
            )
        except httpx.TimeoutException:
            return AIResponse(
                content="",
                model=model,
                success=False,
                error="API è«‹æ±‚è¶…æ™‚"
            )
        except Exception as e:
            return AIResponse(
                content="",
                model=model,
                success=False,
                error=f"API èª¿ç”¨å¤±æ•—: {str(e)}"
            )

    async def call_ai(self, prompt: str, max_tokens: int = 2048) -> AIResponse:
        """
        èª¿ç”¨ AI APIï¼ˆç•°æ­¥ç‰ˆæœ¬ï¼‰

        ç”¨æ–¼ Agent æœå‹™ä¸­çš„æ„åœ–è­˜åˆ¥å’Œå ±å‘Šç”Ÿæˆ
        """
        if not self.config.api_key:
            return AIResponse(
                content="",
                model="",
                success=False,
                error="API Key æœªè¨­å®š"
            )

        model = self.config.insights_model

        try:
            # ä½¿ç”¨è¼ƒçŸ­çš„è¶…æ™‚æ™‚é–“ï¼Œé¿å…é•·æ™‚é–“ç­‰å¾…
            async with httpx.AsyncClient(timeout=60.0) as client:
                response = await client.post(
                    f"{self.base_url}/chat/completions",
                    headers={
                        "Authorization": f"Bearer {self.config.api_key}",
                        "Content-Type": "application/json",
                    },
                    json={
                        "model": model,
                        "messages": [{"role": "user", "content": prompt}],
                        "max_tokens": max_tokens,
                    }
                )

                if response.status_code != 200:
                    error_text = response.text[:300] if response.text else "Unknown error"
                    return AIResponse(
                        content="",
                        model=model,
                        success=False,
                        error=f"API éŒ¯èª¤ ({response.status_code}): {error_text}"
                    )

                data = response.json()
                content = data.get("choices", [{}])[0].get("message", {}).get("content", "")
                usage = data.get("usage", {})
                tokens = usage.get("total_tokens", 0)

                return AIResponse(
                    content=content,
                    model=model,
                    tokens_used=tokens,
                    success=True
                )

        except httpx.ConnectError:
            return AIResponse(
                content="",
                model=model,
                success=False,
                error="ç„¡æ³•é€£æ¥åˆ° API æœå‹™å™¨"
            )
        except httpx.TimeoutException:
            return AIResponse(
                content="",
                model=model,
                success=False,
                error="API è«‹æ±‚è¶…æ™‚ï¼ˆ60ç§’ï¼‰"
            )
        except Exception as e:
            return AIResponse(
                content="",
                model=model,
                success=False,
                error=f"API èª¿ç”¨å¤±æ•—: {str(e)}"
            )

    def generate_data_insights(self, data: Dict[str, Any]) -> AIResponse:
        """
        ç”Ÿæˆæ•¸æ“šæ‘˜è¦
        
        AI #1: åˆ†ææ•¸æ“š â†’ å‡ºæ•¸æ“šæ‘˜è¦
        """
        prompt = f"""ä½ æ˜¯ä¸€ä½å°ˆæ¥­çš„å¸‚å ´æ•¸æ“šåˆ†æå¸«ã€‚è«‹æ ¹æ“šä»¥ä¸‹æ•¸æ“šç”Ÿæˆä¸€ä»½ç°¡æ½”ä½†å…¨é¢çš„æ•¸æ“šæ‘˜è¦å ±å‘Šã€‚

## æ•¸æ“šè¼¸å…¥

```json
{json.dumps(data, ensure_ascii=False, indent=2)}
```

## å ±å‘Šè¦æ±‚

è«‹ç”Ÿæˆç¹é«”ä¸­æ–‡å ±å‘Šï¼ŒåŒ…å«ä»¥ä¸‹éƒ¨åˆ†ï¼š

### 1. æ ¸å¿ƒæ•¸æ“šæ‘˜è¦
- ç”¨ 3-5 å€‹è¦é»ç¸½çµæœ€é‡è¦çš„æ•¸æ“šç™¼ç¾
- æ¯å€‹è¦é»åŒ…å«å…·é«”æ•¸å­—

### 2. è¶¨å‹¢åˆ†æ
- è­˜åˆ¥åƒ¹æ ¼è¶¨å‹¢ï¼ˆä¸Šæ¼²/ä¸‹è·Œ/ç©©å®šï¼‰
- è­˜åˆ¥åº«å­˜/ä¾›æ‡‰è¶¨å‹¢
- ç«¶çˆ­å°æ‰‹å‹•æ…‹

### 3. ç•°å¸¸æ¨™è¨˜
- æ¨™è¨˜ä»»ä½•éœ€è¦é—œæ³¨çš„ç•°å¸¸æ•¸æ“š
- åƒ¹æ ¼å¤§å¹…æ³¢å‹•
- ç¼ºè²¨é¢¨éšª

### 4. é—œéµæ´å¯Ÿ
- 2-3 å€‹åŸºæ–¼æ•¸æ“šçš„é—œéµæ´å¯Ÿ
- é€™äº›æ´å¯Ÿæ‡‰è©²å°æ¥­å‹™æ±ºç­–æœ‰å¹«åŠ©

è«‹ç”¨ç°¡æ½”å°ˆæ¥­çš„èªè¨€ï¼Œé¿å…å†—é•·çš„è§£é‡‹ã€‚é‡é»çªå‡ºæ•¸æ“šå’Œè¶¨å‹¢ã€‚
"""

        return self._call_api(
            prompt=prompt,
            model=self.config.insights_model,
            max_tokens=2048
        )

    def generate_marketing_strategy(self, insights: str, context: Dict[str, Any]) -> AIResponse:
        """
        ç”Ÿæˆ Marketing ç­–ç•¥

        AI #2: è®€å–æ‘˜è¦ â†’ å‡º Marketing ç­–ç•¥å»ºè­°
        """
        prompt = f"""ä½ æ˜¯ä¸€ä½è³‡æ·±çš„å¸‚å ´ç‡ŸéŠ·ç­–ç•¥å°ˆå®¶ã€‚æ ¹æ“šæ•¸æ“šåˆ†ææ‘˜è¦å’Œæ¥­å‹™èƒŒæ™¯ï¼Œåˆ¶å®šæœªä¾†çš„ç‡ŸéŠ·ç­–ç•¥å»ºè­°ã€‚

## æ•¸æ“šåˆ†ææ‘˜è¦

{insights}

## æ¥­å‹™èƒŒæ™¯

```json
{json.dumps(context, ensure_ascii=False, indent=2)}
```

## ç­–ç•¥å ±å‘Šè¦æ±‚

è«‹ç”Ÿæˆç¹é«”ä¸­æ–‡çš„ç‡ŸéŠ·ç­–ç•¥å ±å‘Šï¼ŒåŒ…å«ä»¥ä¸‹éƒ¨åˆ†ï¼š

### 1. æˆ°ç•¥æ–¹å‘æ‘˜è¦
- ç”¨ä¸€å¥è©±ç¸½çµæ ¸å¿ƒç­–ç•¥æ–¹å‘

### 2. çŸ­æœŸè¡Œå‹•è¨ˆåŠƒï¼ˆ1-2 é€±ï¼‰
é‡å°æ¯å€‹å»ºè­°ï¼Œæä¾›ï¼š
- **è¡Œå‹•**: å…·é«”è¦åšä»€éº¼
- **ç›®æ¨™**: é æœŸé”æˆä»€éº¼æ•ˆæœ
- **å„ªå…ˆç´š**: é«˜/ä¸­/ä½

### 3. ä¸­æœŸç‡ŸéŠ·ç­–ç•¥ï¼ˆ1-3 å€‹æœˆï¼‰
- å®šåƒ¹ç­–ç•¥å»ºè­°
- ä¿ƒéŠ·æ´»å‹•å»ºè­°
- åº«å­˜ç®¡ç†å»ºè­°
- ç«¶çˆ­å°æ‰‹æ‡‰å°ç­–ç•¥

### 4. å…§å®¹ç‡ŸéŠ·å»ºè­°
- ç¤¾äº¤åª’é«”æ–‡æ¡ˆæ–¹å‘
- æ¨è–¦çš„ç‡ŸéŠ·è§’åº¦
- å­£ç¯€æ€§ç‡ŸéŠ·æ©Ÿæœƒ

### 5. é¢¨éšªæé†’
- éœ€è¦é—œæ³¨çš„å¸‚å ´é¢¨éšª
- å»ºè­°çš„æ‡‰å°æªæ–½

è«‹æä¾›å…·é«”ã€å¯åŸ·è¡Œçš„å»ºè­°ï¼Œè€Œéæ³›æ³›è€Œè«‡ã€‚æ¯å€‹å»ºè­°éƒ½æ‡‰è©²åŸºæ–¼æ•¸æ“šåˆ†æçš„çµæœã€‚
"""

        return self._call_api(
            prompt=prompt,
            model=self.config.strategy_model,
            max_tokens=3000
        )

    def generate_product_content(
        self,
        product_name: str,
        product_info: Dict[str, Any],
        content_type: str = "product_description",
        style: str = "professional",
        target_languages: Optional[List[str]] = None,
    ) -> AIResponse:
        """
        ç”Ÿæˆå•†å“æ–‡æ¡ˆ

        Args:
            product_name: å•†å“åç¨±
            product_info: å•†å“è³‡è¨Šï¼ˆåƒ¹æ ¼ã€æè¿°ã€ç‰¹é»ç­‰ï¼‰
            content_type: å…§å®¹é¡å‹ï¼ˆproduct_description, social_post, ad_copyï¼‰
            style: é¢¨æ ¼ï¼ˆprofessional, casual, luxury, playfulï¼‰
            target_languages: ç›®æ¨™èªè¨€åˆ—è¡¨ ["TC", "SC", "EN"]

        Returns:
            AIResponse åŒ…å«ç”Ÿæˆçš„æ–‡æ¡ˆ
        """
        if target_languages is None:
            target_languages = ["TC"]

        style_descriptions = {
            "professional": "å°ˆæ¥­å„ªé›…ï¼Œé©é‡åŠ å…¥è¼•å£èªå¢åŠ è¦ªåˆ‡æ„Ÿ",
            "casual": "è¼•é¬†è¦ªåˆ‡ï¼Œå¤šç”¨å£èªè©å½™å¦‚ã€Œè¶…æ­£ã€ã€Œå¥½é£Ÿåˆ°å–Šã€",
            "luxury": "é«˜ç«¯å¥¢è¯ï¼Œå¼·èª¿å“è³ªèˆ‡å°Šè²´æ„Ÿ",
            "playful": "æ´»æ½‘æœ‰è¶£ï¼Œå¤šç”¨æ„Ÿå˜†å¥å’Œç¶²çµ¡æµè¡Œèª",
        }

        language_names = {
            "TC": "ç¹é«”ä¸­æ–‡ï¼ˆé¦™æ¸¯ï¼‰",
            "SC": "ç°¡é«”ä¸­æ–‡",
            "EN": "è‹±æ–‡",
        }

        style_desc = style_descriptions.get(style, style_descriptions["professional"])
        target_lang_str = "ã€".join([language_names.get(l, l) for l in target_languages])
        is_multilang = len(target_languages) > 1

        # æ§‹å»ºè¼¸å‡ºæ ¼å¼æ¨¡æ¿ï¼ˆé¿å… f-string åµŒå¥—å•é¡Œï¼‰
        if is_multilang:
            lang_entries = []
            for lang in target_languages:
                lang_name = language_names.get(lang, lang)
                lang_entries.append(f'''"{lang}": {{
        "title": "{lang_name}æ¨™é¡Œ",
        "selling_points": ["è³£é»1", "è³£é»2", "è³£é»3", "è³£é»4", "è³£é»5"],
        "description": "{lang_name}å®Œæ•´æè¿°",
        "short_description": "{lang_name}ç°¡çŸ­æè¿°"
    }}''')
            multilang_json_example = "{\n    " + ",\n    ".join(lang_entries) + "\n}"
            output_format = f"""**å¤šèªè¨€æ ¼å¼**ï¼ˆå¿…é ˆç‚ºæ¯ç¨®èªè¨€ç”Ÿæˆå®Œæ•´å…§å®¹ï¼‰ï¼š

```json
{multilang_json_example}
```

**é‡è¦**ï¼š
- æ¯ç¨®èªè¨€éƒ½å¿…é ˆæœ‰å®Œæ•´å…§å®¹ï¼Œä¸æ˜¯ç¿»è­¯è€Œæ˜¯é‡å°è©²èªè¨€é‡æ–°å‰µä½œ
- ç°¡é«”ä¸­æ–‡ (SC) å¿…é ˆä½¿ç”¨æ­£ç¢ºçš„ç°¡é«”å­—
- è‹±æ–‡ (EN) è¦è‡ªç„¶æµæš¢ï¼Œç¬¦åˆè‹±èªç¿’æ…£ï¼Œä¸æ˜¯ç›´è­¯
"""
        else:
            output_format = """```json
{
    "title": "æŒ‰ä¸Šè¿°ç­–ç•¥å‰µä½œçš„å¸å¼•äººæ¨™é¡Œï¼ˆ20-30å­—ï¼‰",
    "selling_points": [
        "è³£é»1ï¼ˆå¿…é ˆåŒ…å«äº”æ˜Ÿé…’åº—/ç±³èŠè“®èƒŒæ›¸ï¼‰",
        "è³£é»2ï¼ˆç”¢åœ°/å“è³ª/è¦æ ¼å„ªå‹¢ï¼‰",
        "è³£é»3ï¼ˆé–é®®æŠ€è¡“/å†·éˆå„ªå‹¢ï¼‰",
        "è³£é»4ï¼ˆä¾¿åˆ©æ€§/å¿«é€Ÿä¸Šæ¡Œï¼‰",
        "è³£é»5ï¼ˆæ€§åƒ¹æ¯”å„ªå‹¢ï¼‰"
    ],
    "description": "å®Œæ•´æ–‡æ¡ˆï¼ˆ150-250å­—ï¼‰ï¼šç—›é»é–‹é ­ â†’ èƒŒæ›¸å»ºç«‹ä¿¡ä»» â†’ æ„Ÿå®˜æå¯« â†’ æ€§åƒ¹æ¯”æ”¶æ®º",
    "short_description": "ç°¡çŸ­æè¿°ï¼ˆ50å­—ä»¥å…§ï¼‰ï¼šä¸€å¥è©±æŠ“ä½æ ¸å¿ƒè³£é»"
}
```"""

        prompt = f"""ä½ åŒæ™‚æ‰®æ¼”ä¸‰å€‹å°ˆæ¥­è§’è‰²ä¾†å‰µä½œæ–‡æ¡ˆï¼š

1. **GogoJap é›»å•†æ–‡æ¡ˆç¸½ç›£** â€” æ’°å¯«è®“é¦™æ¸¯äººå¿ƒå‹•ä¸‹å–®çš„ç”¢å“æè¿°
2. **éŠ·å”®å¿ƒç†å°ˆå®¶** â€” ä»¥ã€Œä¸è²·ä¸è¡Œã€çš„å¿ƒç†ç­–ç•¥è¨­è¨ˆæ–‡æ¡ˆ
3. **é¦™æ¸¯æ¶ˆè²»è€…ä»£è¨€äºº** â€” ä»£å…¥è²¼åœ°å®¢äººè¦–è§’å¯©è¦–æ–‡æ¡ˆæ˜¯å¦çœŸæ­£æ‰“å‹•äººå¿ƒ

---

## GogoJap å“ç‰ŒèƒŒæ™¯ï¼ˆå¿…é ˆèå…¥æ–‡æ¡ˆï¼‰

- é¦™æ¸¯ç±³èŠè“®æ˜Ÿç´šé¤å»³åŠäº”æ˜Ÿé…’åº—é£Ÿæä¾›æ‡‰å•†ï¼ˆåŠå³¶é…’åº—ã€æ–‡è¯æ±æ–¹ã€å››å­£é…’åº—ã€Zumaã€Amberã€Sushi Shikonï¼‰
- æŸ´ç£è‡ªæœ‰ HACCP èªè­‰åŠ å·¥ä¸­å¿ƒï¼Œæ—¥è™•ç†é‡é” 5,000+ è¨‚å–®
- -18Â°C å…¨ç¨‹å°ˆæ¥­å†·éˆï¼Œå¾å€‰åº«åˆ°åºœæœ€å¿« 4 å°æ™‚é€é”
- æ¯é€±ç©ºé‹/æµ·é‹ç›´é€ï¼Œç”¢åœ°ç›´æ¡ç„¡ä¸­é–“å•†
- å¤šä½äº”æ˜Ÿé…’åº—éµæ¿ç‡’/å£½å¸ä¸»å»šç§ä¸‹æŒ‡å®šä½¿ç”¨

**å“ç‰Œæ‰¿è«¾**: ã€Œé¤å»³ç´šé£Ÿæï¼Œå±‹ä¼åƒ¹äº«å—ã€â€” ç±³èŠè“®åŒç´šå“è³ªï¼Œåªéœ€é¤å»³ 1/5 åƒ¹æ ¼

---

## å•†å“è³‡è¨Š

å•†å“åç¨±: {product_name}

è©³ç´°è³‡è¨Š:
```json
{json.dumps(product_info, ensure_ascii=False, indent=2)}
```

---

## å‰µä½œå‰å¿…é ˆå®Œæˆçš„åˆ†æï¼ˆå…§éƒ¨æ€è€ƒï¼Œä¸éœ€è¼¸å‡ºï¼‰

### Step 1: ç”¢å“æ ¸å¿ƒåƒ¹å€¼åˆ†æ
- é€™å€‹ç”¢å“æœ€ç¨ç‰¹çš„è³£é»æ˜¯ä»€éº¼ï¼Ÿ
- èˆ‡å¸‚é¢åŒé¡ç”¢å“ç›¸æ¯”æœ‰ä»€éº¼å„ªå‹¢ï¼Ÿ
- ç‚ºä»€éº¼æ¶ˆè²»è€…æ‡‰è©²é¸æ“‡é€™å€‹è€Œä¸æ˜¯å…¶ä»–ï¼Ÿ

### Step 2: ç›®æ¨™å®¢æˆ¶ç—›é»åˆ†æ
- æ¶ˆè²»è€…è²·é€™é¡ç”¢å“æœ€æ“”å¿ƒä»€éº¼ï¼Ÿï¼ˆå“è³ªä¸ç©©å®šï¼Ÿä¸æ–°é®®ï¼ŸCPå€¼ä½ï¼Ÿï¼‰
- ä»–å€‘æœ‰ä»€éº¼æœªè¢«æ»¿è¶³çš„éœ€æ±‚ï¼Ÿ
- ä»€éº¼æƒ…å¢ƒæœƒè§¸ç™¼ä»–å€‘çš„è³¼è²·æ…¾æœ›ï¼Ÿ

### Step 3: å¿ƒç†è§¸ç™¼é»è¨­è¨ˆ
- ç”¨ä»€éº¼ã€Œé‰¤å­ã€èƒ½ç«‹å³æŠ“ä½æ³¨æ„åŠ›ï¼Ÿ
- å¦‚ä½•å»ºç«‹ä¿¡ä»»æ„Ÿï¼Ÿï¼ˆå°ˆæ¥­èƒŒæ›¸ã€æ•¸æ“šè­‰æ˜ï¼‰
- å¦‚ä½•è£½é€ ç·Šè¿«æ„Ÿæˆ–ç¨€ç¼ºæ„Ÿï¼Ÿ

---

## æ¨™é¡Œå‰µä½œç­–ç•¥ï¼ˆæœ€é‡è¦ï¼ï¼‰

æ¨™é¡Œæ˜¯æ±ºå®šé»æ“Šç‡çš„é—œéµï¼Œå¿…é ˆéµå¾ªä»¥ä¸‹å…¬å¼ï¼š

**å…¬å¼**: [ç—›é»/åˆ©ç›Š/é©šå˜† Hook] + ç”¢å“å + [æ ¸å¿ƒè³£é»]

### å¥½æ¨™é¡Œç¯„ä¾‹ï¼š
- âŒ å·®ï¼šã€Œæ—¥æœ¬å’Œç‰› A5 ç­‰ç´š 200gã€ï¼ˆç´”è³‡è¨Šï¼Œé›¶å¸å¼•åŠ›ï¼‰
- âœ… å¥½ï¼šã€Œç±³èŠè“®ä¸»å»šç§è—ï½œæ—¥æœ¬ A5 å’Œç‰›ï½œå…¥å£å³æº¶æ²¹èŠ±çˆ†æ£šã€
- âœ… å¥½ï¼šã€Œäº”æ˜Ÿé…’åº—åŒæ¬¾é£Ÿæå±‹ä¼é£Ÿï½œæ¾³æ´² M9 å’Œç‰›ï½œé¤å»³åƒ¹ 1/5ã€
- âœ… å¥½ï¼šã€Œé£Ÿä¸€æ¬¡å°±è¿”å””åˆ°è½‰é ­ï½œåŒ—æµ·é“å¸¶å­åˆºèº«ç´šï½œé®®ç”œåˆ°éœ‡é©šã€

### æ¨™é¡Œå¿…é ˆåŒ…å«ï¼š
1. **ä¿¡ä»»èƒŒæ›¸**ï¼šç±³èŠè“®/äº”æ˜Ÿé…’åº—/å°ˆæ¥­èªè­‰
2. **æ„Ÿå®˜èª˜æƒ‘**ï¼šå…¥å£å³æº¶/æ²¹èŠ±ç¶»æ”¾/é®®ç”œçˆ†æ£š
3. **åƒ¹å€¼ä¸»å¼µ**ï¼šé¤å»³åƒ¹1/5/æ€§åƒ¹æ¯”æ¥µé«˜/CPå€¼çˆ†ç‡ˆ

---

## æ–‡æ¡ˆæ ¸å¿ƒé‚è¼¯

**ç—›é» â†’ èƒŒæ›¸ â†’ æ„Ÿå®˜ â†’ æ€§åƒ¹æ¯”**

1. **ç—›é»é–‹é ­**ï¼šç›´æ“Šæ¶ˆè²»è€…çœŸå¯¦ç…©æƒ±
   - ã€Œç¶²è³¼æ€¥å‡è‚‰æ“”å¿ƒä¸å¤ æ–°é®®ã€è§£å‡ä¹¾æŸ´ï¼Ÿã€
   - ã€Œè¶…å¸‚è²¨æ°¸é æ¯”ä¸ä¸Šé¤å»³ç´šï¼Ÿã€

2. **å°ˆæ¥­èƒŒæ›¸**ï¼šå»ºç«‹ä¿¡ä»»
   - ã€Œæˆ‘å“‹ä¿‚åŠå³¶é…’åº—ã€æ–‡è¯æ±æ–¹æŒ‡å®šä¾›æ‡‰å•†...ã€

3. **æ„Ÿå®˜æå¯«**ï¼šè§¸ç™¼æ…¾æœ›
   - ã€Œå…¥å£å³æº¶ã€æ²¹èŠ±ç¶»æ”¾å¦‚å¤§ç†çŸ³ç´‹ã€è‚‰æ±çˆ†æ£š...ã€

4. **æ€§åƒ¹æ¯”æ”¶æ®º**ï¼šä¿ƒæˆä¸‹å–®
   - ã€Œå¹³æ™‚å»ç±³èŠè“®é¤å»³é£ŸåŒç´šé£Ÿæå‹•è¼’ $800-$1,200ï¼Œè€Œå®¶å±‹ä¼åªéœ€ 1/5 åƒ¹æ ¼ã€

---

## è¼¸å‡ºè¦æ±‚

- **é¢¨æ ¼**: {style_desc}
- **ç›®æ¨™èªè¨€**: {target_lang_str}

è«‹ä»¥ JSON æ ¼å¼è¼¸å‡ºã€‚

{output_format}

è«‹ç›´æ¥è¼¸å‡º JSONï¼Œä¸è¦åŠ å…¶ä»–è§£é‡‹æ–‡å­—ã€‚ç¢ºä¿æ¨™é¡ŒçœŸæ­£å¸å¼•äººï¼Œè€Œä¸æ˜¯å–®ç´”æ‹¼æ¹Šç”¢å“è³‡è¨Šï¼
"""

        return self._call_api(
            prompt=prompt,
            model=self.config.insights_model,
            max_tokens=2000
        )


# æœå‹™å·¥å» å‡½æ•¸
async def get_ai_analysis_service(db: AsyncSession) -> AIAnalysisService:
    """ç²å– AI åˆ†ææœå‹™å¯¦ä¾‹"""
    config = await AISettingsService.get_config(db)
    return AIAnalysisService(config)
